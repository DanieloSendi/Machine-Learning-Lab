{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbtKaCGqL1cyiGNaO8b4SO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanieloSendi/MachineLearning/blob/main/Lab1_Getting_Started_with_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Getting Started with DNN**"
      ],
      "metadata": {
        "id": "RV0ECHCpL1ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Firstly, import Keras (based on the Python/Tensorflow version):"
      ],
      "metadata": {
        "id": "ehqgAG-7NuL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-7vcu_8Ksso",
        "outputId": "81083d7b-7568-4ae0-d790-e9b20043ac97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network architecture"
      ],
      "metadata": {
        "id": "dPlzdJM8Lwyq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voU_z1mQEciJ"
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Training\n",
        "Once the model architecture is defined, the learning process can be configured in the compilation step. We specify the optimizer, loss function, and metrics."
      ],
      "metadata": {
        "id": "lgoCnzqqL6No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7cZ2p3sQMA78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation\n",
        "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the [0, 1] interval. Our training images are being stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. Please transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1.\n",
        "Necessary functions: `reshape` and `astype`.\n",
        "Perform it for both train and test examples."
      ],
      "metadata": {
        "id": "zqiG374ZMJRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: reshape and transform the data\n",
        "import numpy as np\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255"
      ],
      "metadata": {
        "id": "GyuRKUHxMO6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because of we use categorical_crossentropy loss function we need to convert data format:"
      ],
      "metadata": {
        "id": "4DIlyTwUNXqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "nfDBk02PNYYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the model\n",
        "\n",
        "To train the network we call the fit method of the network with parameters epochs and batch_size. Set epochs to 5, and batch_size to 128."
      ],
      "metadata": {
        "id": "SKuvrTc3MPMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: fit the model\n",
        "\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANiUNHLdMQn4",
        "outputId": "2ea1db2f-774a-40d4-8a14-b32e9a45ba4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 6s 11ms/step - loss: 0.2670 - accuracy: 0.9240\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1092 - accuracy: 0.9679\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0711 - accuracy: 0.9791\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0511 - accuracy: 0.9849\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0388 - accuracy: 0.9882\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb24062a680>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network evaluation\n",
        "Two quantities are being displayed during training: the “loss” of the network over the training data, and the accuracy of the network over the training data. We quickly reach an accuracy of 0.989 (i.e. 98.9%) on the training data. Now let's check that our model performs well on the test set too:"
      ],
      "metadata": {
        "id": "6jg9Jq_pMCzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "\n",
        "print('test_acc:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh8CMCUEMCnI",
        "outputId": "f7c4906f-7922-4563-ab5c-d3e4bbea6d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0649 - accuracy: 0.9805\n",
            "test_acc: 0.9804999828338623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our test set accuracy turns out to be 98,04% – that's quite a bit lower than the training set accuracy.\n",
        "This gap between training accuracy and test accuracy is an example of “overfitting”, the fact that machine learning models tend to perform worse on new data than on their training data."
      ],
      "metadata": {
        "id": "vnTWEayzTKiW"
      }
    }
  ]
}